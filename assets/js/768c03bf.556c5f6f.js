"use strict";(self.webpackChunkmy_docs=self.webpackChunkmy_docs||[]).push([[7053],{3905:(e,t,a)=>{a.d(t,{Zo:()=>h,kt:()=>f});var r=a(7294);function i(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function n(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?n(Object(a),!0).forEach((function(t){i(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):n(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,i=function(e,t){if(null==e)return{};var a,r,i={},n=Object.keys(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||(i[a]=e[a]);return i}(e,t);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(r=0;r<n.length;r++)a=n[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(i[a]=e[a])}return i}var s=r.createContext({}),c=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},h=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},d="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var a=e.components,i=e.mdxType,n=e.originalType,s=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),d=c(a),p=i,f=d["".concat(s,".").concat(p)]||d[p]||u[p]||n;return a?r.createElement(f,l(l({ref:t},h),{},{components:a})):r.createElement(f,l({ref:t},h))}));function f(e,t){var a=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var n=a.length,l=new Array(n);l[0]=p;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[d]="string"==typeof e?e:i,l[1]=o;for(var c=2;c<n;c++)l[c]=a[c];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}p.displayName="MDXCreateElement"},766:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>n,metadata:()=>o,toc:()=>c});var r=a(7462),i=(a(7294),a(3905));const n={},l="High level Transaction Flows",o={unversionedId:"cache/High_level_Transaction_Flows",id:"cache/High_level_Transaction_Flows",title:"High level Transaction Flows",description:"In this chapter will describe the high-level transaction Flow.",source:"@site/docs/cache/High_level_Transaction_Flows.md",sourceDirName:"cache",slug:"/cache/High_level_Transaction_Flows",permalink:"/fpga_mafia_wiki/docs/cache/High_level_Transaction_Flows",draft:!1,editUrl:"https://github.com/FPGA-MAFIA/fpga_mafia_wiki/tree/main/docs/cache/High_level_Transaction_Flows.md",tags:[],version:"current",frontMatter:{}},s={},c=[{value:"Evicting Cache-Line",id:"evicting-cache-line",level:2},{value:"Core Write Hit",id:"core-write-hit",level:2},{value:"Core Read Hit",id:"core-read-hit",level:2},{value:"Core Read Miss",id:"core-read-miss",level:2},{value:"Stall",id:"stall",level:2},{value:"Re-Issue buffer**",id:"re-issue-buffer",level:2},{value:"FSM Errors",id:"fsm-errors",level:2},{value:"MRU",id:"mru",level:2},{value:"FILL",id:"fill",level:2}],h={toc:c},d="wrapper";function u(e){let{components:t,...a}=e;return(0,i.kt)(d,(0,r.Z)({},h,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"high-level-transaction-flows"},"High level Transaction Flows"),(0,i.kt)("p",null,"In this chapter will describe the high-level transaction Flow."),(0,i.kt)("h2",{id:"evicting-cache-line"},"Evicting Cache-Line"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Silent Evict:")," When de-allocating a non-modified CL without notifying the FM."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Clean Evict:")," When de-allocating a non-modified CL and Writing it Back to FM."),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"*Note:")," In this Cache Architecture, we do not support \u201cClean evict\u201d.*"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Dirty Evict:")," When de-allocating a modified CL from the Cache, and writing it back to FM.")),(0,i.kt)("h2",{id:"core-write-hit"},"Core Write Hit"),(0,i.kt)("p",null,"core2cache","_","req writes that were accepted to the TQ, and hit the tag array will result in cache write by hitting an existing CL\n.3 CORE WRITE MISS**\ncore2cache","_","req writes that were accepted to the TQ, may miss the tag array, and will result in cache write by allocating a new way in the Cache.\nIf the allocated way (the \u201cvictim\u201d) was modified, send a Dirty Evict Write Back (WB) to FM.\nIf the allocated way (the \u201cvictim\u201d) was clean (non-modified), simply do a Silent Evict."),(0,i.kt)("h2",{id:"core-read-hit"},"Core Read Hit"),(0,i.kt)("p",null,"core2cache","_","req read CL that ",(0,i.kt)("strong",{parentName:"p"},"hit")," the cache, will respond with data on the \u201ccache2core","_","rsp\u201d interface in deterministic 2 Cycle Latency. There is no need to \u201callocate\u201d a new way in the cache, and no \u201cvictim\u201d to send as WB to FM."),(0,i.kt)("h2",{id:"core-read-miss"},"Core Read Miss"),(0,i.kt)("p",null,"core2cache","_","req read CL that ",(0,i.kt)("strong",{parentName:"p"},"misses")," the cache will eventually respond with data on the \u201ccache2core","_","rsp\u201d interface. "),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"A stall will happen, stopping new requests from the core temporarily."),(0,i.kt)("li",{parentName:"ol"},"The miss will trigger a \u201ccache2fm","_","rd","_","req","_","q3,\u201d which will send the read request to the Far-Memory (FM) & eventually respond with the fm2cache","_","rd","_","rsp \u2013 also known as \u201cFill\u201d.\nThe response from FM has two destinations:")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Cache: \tThe fm2cache","_","rd","_","rsp will \u201cfill\u201d the allocated Cache Way"),(0,i.kt)("li",{parentName:"ul"},"Core: \tThe fm2cache","_","rd","_","rsp will be sent as a \u201ccache2core","_","rsp\u201d to serve the origin \t\tcore2cache","_","req.")),(0,i.kt)("h2",{id:"stall"},"Stall"),(0,i.kt)("p",null,"Stall is a situation where we do not allow new requests from the core temporarily, causing a delay in the execution of the program. Our cache will enter stall mode in two scenarios\nThe first will be when our TQ is full, it will set the \u201cstall\u201d signal to the core, stopping new requests from being sent.\nThe second is in the case of a Read Miss. This will result in a stall, as the processing of the request is temporarily stopped while the data is retrieved from main memory."),(0,i.kt)("h2",{id:"re-issue-buffer"},"Re-Issue buffer**"),(0,i.kt)("p",null,'We saw that in the case of \u201cRead Miss", the Stall will be set, and this will temporarily stop the processing of request. '),(0,i.kt)("p",null,"This means, we support a single \u201coutstanding\u201d core read miss request"),(0,i.kt)("p",null,"In case of Back2Back request, In the q2 cycle we set the Stall due to the Read miss, but Q1 already was sent from core->cache.\nThis Q1 request must be rejected by TQ & Pipe.\nYet, we do not want to lose That rejected request.\nWe Will save them and take care of them after the stall is unset. (Note: during the stall we are not expecting any new request from Core.)\nFor that purpose, we will use the \u201cre-issue buffer\u201d. It will store the last request that arrived during the stall.\nOnce the Read fill response arrives and sent to Core, we will check if the Re-issue buffer is empty. If it is, we have nothing more to do. If it is not empty, it will mean we have a request that is waiting to be handled and we will re-issue it to our TQ & pipe from this specific buffer."),(0,i.kt)("h2",{id:"fsm-errors"},"FSM Errors"),(0,i.kt)("p",null,"Entering the \u201cerror state\u201d in the transaction queue (TQ) State Machine is an \u201c",(0,i.kt)("strong",{parentName:"p"},"uncorrectable")," ",(0,i.kt)("strong",{parentName:"p"},"error\u201d")," that can cause data corruption & coherent inconsistency.\nThis state is for debugging and security to ensure the Cache is not abused.\nEntering the \u201cerror state\u201d is un-recoverable and will cause a \u201cBlue-Screen of Death\u201d."),(0,i.kt)("h2",{id:"mru"},"MRU"),(0,i.kt)("p",null,"In this project we will use the Pseudo Most Recently Used (P-MRU) replacement policy to determine which entry to remove when our cache is full and a new entry needs to be added. In this policy, the newest entry is placed at the head of the cache and whenever it is full, the item at the end of the cache is the one that will be replaced. It will provide an efficient way of managing our cache memory ensuring that the most frequently used data is readily available in the cache.\nTo be more specific we are using Bit-PLRU, it will store one status bits per way. Every access to a way in our set will set its MRU-bits to 1 indicating the way was recently used. Whenever the last 0 bit of a set\u2019s status bits is set to 1, all other bits are reset to 0. "),(0,i.kt)("h2",{id:"fill"},"FILL"),(0,i.kt)("p",null,"In case of miss, the cache will send a fill request to the Far Memory to bring the corresponding Cache-Line to the cache.\n\u201cfill","_","modified\u201d bit will inform us that the actual fill is happening because of a write miss and that the specific CL will be updated with the new word\n\u201cfill","_","rd\u201d bit will inform us that the fill is happening because of a read miss and that we need to return the value to the core after we bring it in the cache. It will also be set in case of read after write to the same CL. As we have already explained in this case the read miss will not send a new fill request so this bit will inform the tq to also send the read response after the fill (of the write request) arrive."))}u.isMDXComponent=!0}}]);